{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr1L2lLUOQ7n1sytv+MzTF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrathamKumar125/AI-Voice-Assistance/blob/master/AI_Voice_Assistance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukMaO5beT34L",
        "outputId": "b3a32d22-1a4b-4848-921f-7a5ffb619d3e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from transformers import AutoTokenizer\n",
        "from llama_index.core import Settings\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import time\n",
        "from llama_index.llms.text_generation_inference import TextGenerationInference\n",
        "import whisper\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "\n",
        "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
        "import soundfile as sf\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_KqGYFA4L9k",
        "outputId": "556fcafb-c2c9-4025-8189-934f16897644"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "def translate_audio(audio):\n",
        "\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions(language='en', task=\"transcribe\", temperature=0)\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyNqw1dxuQz-",
        "outputId": "dc644a8d-8916-4651-b170-cfb00fc97b1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 73.7MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_to_prompt(messages):\n",
        "    # Default system message for a chatbot\n",
        "    default_system_prompt = \"You are an AI chatbot designed to assist with user queries in a friendly and conversational manner.\"\n",
        "\n",
        "    prompt = default_system_prompt + \"\\n\"\n",
        "\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "            prompt += f\"\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'user':\n",
        "            prompt += f\"\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'assistant':\n",
        "            prompt += f\"\\n{message.content}</s>\\n\"\n",
        "\n",
        "    # Ensure we start with a system prompt, insert blank if needed\n",
        "    if not prompt.startswith(\"\\n\"):\n",
        "        prompt = \"\\n</s>\\n\" + prompt\n",
        "\n",
        "    # Add final assistant prompt\n",
        "    prompt = prompt + \"\\n\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    return f\"<|system|>\\n</s>\\n<|user|>\\n{completion}</s>\\n<|assistant|>\\n\"\n",
        "\n",
        "Settings.llm = TextGenerationInference(\n",
        "    model_url=\"https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    token=userdata.get(\"hf_key\"),\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt\n",
        ")\n"
      ],
      "metadata": {
        "id": "PUgta_UkgJHc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_response(t):\n",
        "    time.sleep(1)  # Adjust the delay as needed\n",
        "    response = Settings.llm.complete(t)\n",
        "    message = response.text\n",
        "    return  message"
      ],
      "metadata": {
        "id": "AZtM-KxvfbZh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_response(text, output_path=\"speech.wav\"):\n",
        "    # Load the processor, model, and vocoder\n",
        "    processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "    model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "    vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "\n",
        "    # Process the input text\n",
        "    inputs = processor(text=text, return_tensors=\"pt\")\n",
        "\n",
        "    # Load xvector containing speaker's voice characteristics\n",
        "    embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "    speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "    # Generate speech\n",
        "    with torch.no_grad():\n",
        "        speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
        "\n",
        "    # Save the audio to a file\n",
        "    sf.write(output_path, speech.numpy(), samplerate=16000)  # Ensure the sample rate matches your needs\n",
        "\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "SjueuwWqa6zp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_(a):\n",
        "    t1 = translate_audio(a)\n",
        "    t2 = text_response(t1)\n",
        "    t3 = audio_response(t2)\n",
        "    return (t1, t2, t3)\n",
        "\n",
        "output_1 = gr.Textbox(label=\"Speech to Text\")\n",
        "output_2 = gr.Textbox(label=\"LLM Output\")\n",
        "output_3 = gr.Audio(label=\"LLM output to audio\")\n",
        "\n",
        "gr.Interface(\n",
        "    title='AI Voice Assistant',\n",
        "    fn=transcribe_,\n",
        "    inputs=[\n",
        "        gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        output_1, output_2, output_3\n",
        "    ]\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "id": "dmcN4OB3Zd7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "e71c3c24-feb3-4ad2-d96f-d706984556b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d35153d4b962f24b3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d35153d4b962f24b3f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe_(\"speech.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFdRHkZifVzJ",
        "outputId": "47681885-c2d0-460e-d6f4-bf4698887ff3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Hello, my dog is cute.',\n",
              " \"That's great to hear! I'm sure your dog is adorable! What's your dog's name and what makes them so cute? Do they have a funny personality or a special feature that makes them stand out? I'd love to hear more about your furry friend!\",\n",
              " 'speech.wav')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8voJKDPcbFQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}